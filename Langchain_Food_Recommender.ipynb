{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raghavan93513/Langchain-Food-Recommender/blob/main/Langchain_Food_Recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Installs, Imports and API Keys"
      ],
      "metadata": {
        "id": "Q24Y-g6h-Bg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN THIS CELL FIRST!\n",
        "!pip install -q langchain==0.0.150 pypdf pandas matplotlib tiktoken textract transformers openai faiss-cpu sentence_transformers"
      ],
      "metadata": {
        "id": "gk2J2sYYjTkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import GPT2TokenizerFast\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain"
      ],
      "metadata": {
        "id": "l-uszlwN641q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-XXX\""
      ],
      "metadata": {
        "id": "E2Buv5Y0uFr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Loading PDFs and chunking with LangChain"
      ],
      "metadata": {
        "id": "RLULMPXa-Hu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You MUST add your PDF to local files in this notebook (folder icon on left hand side of screen)\n",
        "\n",
        "# Simple method - Split by pages\n",
        "loader = PyPDFLoader(\"./RaghavanBestFood.pdf\")\n",
        "pages = loader.load_and_split()\n",
        "print(pages[0])\n",
        "\n",
        "# SKIP TO STEP 2 IF YOU'RE USING THIS METHOD\n",
        "chunks = pages"
      ],
      "metadata": {
        "id": "KH546j3nkFwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Advanced method - Split by chunk\n",
        "\n",
        "# Step 1: Convert PDF to text\n",
        "import textract\n",
        "doc = textract.process(\"./RaghavanBestFood.pdf\")\n",
        "\n",
        "# Step 2: Save to .txt and reopen (helps prevent issues)\n",
        "with open('RaghavanBestFood.txt', 'w') as f:\n",
        "    f.write(doc.decode('utf-8'))\n",
        "\n",
        "with open('RaghavanBestFood.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Step 3: Create function to count tokens\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
        "\n",
        "def count_tokens(text: str) -> int:\n",
        "    return len(tokenizer.encode(text))\n",
        "\n",
        "# Step 4: Split text into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size = 512,\n",
        "    chunk_overlap  = 24,\n",
        "    length_function = count_tokens,\n",
        ")\n",
        "\n",
        "chunks = text_splitter.create_documents([text])"
      ],
      "metadata": {
        "id": "iADY2CXNlNq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of Chunks:\",len(chunks))"
      ],
      "metadata": {
        "id": "ufS78DLX2JW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Result is many LangChain 'Documents' around 500 tokens or less (Recursive splitter sometimes allows more tokens to retain context)\n",
        "type(chunks[0])"
      ],
      "metadata": {
        "id": "KQ_gDkwep4q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of token counts\n",
        "token_counts = [count_tokens(chunk.page_content) for chunk in chunks]\n",
        "token_counts"
      ],
      "metadata": {
        "id": "ox1ystcl2ZnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick data visualization to ensure chunking was successful\n",
        "\n",
        "# Create list of indices for x-axis\n",
        "indices = range(len(token_counts))\n",
        "\n",
        "# Create a bar chart\n",
        "plt.bar(indices, token_counts)\n",
        "\n",
        "# Labeling the bar chart\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Token Counts')\n",
        "plt.title('Bar Chart of Token Counts per Chunk')\n",
        "\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fK31bxDOpz1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Embed text and store embeddings"
      ],
      "metadata": {
        "id": "_IlznUDK-i2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get embedding model\n",
        "embeddings = HuggingFaceEmbeddings()\n",
        "\n",
        "# Create vector database\n",
        "db = FAISS.from_documents(chunks, embeddings)"
      ],
      "metadata": {
        "id": "92ObhTAKnZzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Query to get information about Food Recommendation"
      ],
      "metadata": {
        "id": "2LPwdGDP-nPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create QA chain to integrate similarity search with user queries (answer query from knowledge base)\n",
        "\n",
        "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
        "\n",
        "query = \"What dish should I eat in India and why?\"\n",
        "docs = db.similarity_search(query)\n",
        "\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "id": "1Kv_sM8G5qAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Create Food Recommending Chatbot"
      ],
      "metadata": {
        "id": "U_nH1qoL-w--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Create conversation chain that uses our vectordb as retriver, this also allows for chat history management\n",
        "qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0.5), db.as_retriever())"
      ],
      "metadata": {
        "id": "evF7_Dyhtcaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "\n",
        "def on_submit(_):\n",
        "    query = input_box.value\n",
        "    input_box.value = \"\"\n",
        "\n",
        "    if query.lower() == 'exit':\n",
        "        print(\"Thank you for using the Raghavan's Recommended  Food list chatbot!\")\n",
        "        return\n",
        "\n",
        "    result = qa({\"question\": query, \"chat_history\": chat_history})\n",
        "    chat_history.append((query, result['answer']))\n",
        "\n",
        "    display(widgets.HTML(f'<b>User:</b> {query}'))\n",
        "    display(widgets.HTML(f'<b><font color=\"blue\">Chatbot:</font></b> {result[\"answer\"]}'))\n",
        "\n",
        "print(\"Welcome to the Raghavan's Recommended  Food List Chatbot! Type 'exit' to stop.\")\n",
        "\n",
        "input_box = widgets.Text(placeholder='Please enter your question:')\n",
        "input_box.on_submit(on_submit)\n",
        "\n",
        "display(input_box)"
      ],
      "metadata": {
        "id": "-pHw5siewPNt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}